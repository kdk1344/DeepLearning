{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['biking', 'diving', 'golf', 'juggle', 'jumping', 'riding',\n",
      "       'shooting', 'spiking', 'swing', 'tennis', 'walk'], dtype=object)\n",
      "{'biking': 0,\n",
      " 'diving': 1,\n",
      " 'golf': 2,\n",
      " 'juggle': 3,\n",
      " 'jumping': 4,\n",
      " 'riding': 5,\n",
      " 'shooting': 6,\n",
      " 'spiking': 7,\n",
      " 'swing': 8,\n",
      " 'tennis': 9,\n",
      " 'walk': 10}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              5919312   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 11)                14091     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,933,403\n",
      "Trainable params: 5,872,795\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khj_a\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "LABEL_INT_DICT = np.unique(pd.read_csv('ucf11_train_vid.csv')['label'])\n",
    "LABEL_STR_DICT = {k:v for v, k in enumerate(LABEL_INT_DICT)}\n",
    "pprint(LABEL_INT_DICT)\n",
    "pprint(LABEL_STR_DICT)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n",
    "                   trainable=True),  # Can be True, see below.\n",
    "    tf.keras.layers.Dense(len(LABEL_INT_DICT), activation='softmax')\n",
    "])\n",
    "model.build([None, 256, 256, 3])  # Batch input shape.\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ucf11_weights/10-0.98.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13404/700393014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m model = keras.models.load_model(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;34m'ucf11_weights/10-0.98.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'KerasLayer'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             raise ImportError(\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at ucf11_weights/10-0.98.hdf5"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "model = keras.models.load_model(\n",
    "    'ucf11_weights/10-0.98.hdf5',\n",
    "    custom_objects={'KerasLayer': hub.KerasLayer}\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN  \n",
    "* 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델  \n",
    "* 순환 신경망(Recurrent Neural Network)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              5919312   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,919,312\n",
      "Trainable params: 5,858,704\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(256, 256, 3)),\n",
    "        model.layers[0]\n",
    "    ], name='feature_extractor'\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('UCF11_updated_npy')\n",
    "os.mkdir('UCF11_updated_npy/train')\n",
    "os.mkdir('UCF11_updated_npy/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 10\n",
    "SAVE_DIR = 'UCF11_updated_npy/'\n",
    "train_df = pd.read_csv('ucf11_train_vid.csv')\n",
    "valid_df = pd.read_csv('ucf11_valid_vid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [02:01<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, elem in tqdm(train_df.iterrows(),\n",
    "                   total=len(train_df)):\n",
    "    label = elem['label']\n",
    "    cap = cv2.VideoCapture(\n",
    "        elem['file_path']\n",
    "    )\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_ = frame.copy()\n",
    "        frame_ = cv2.cvtColor(frame_, cv2.COLOR_BGR2RGB)\n",
    "        frame_ = cv2.resize(frame_, (256, 256))\n",
    "        frame_ = frame_.astype('float32')\n",
    "        frame_ = frame_ / 255.\n",
    "\n",
    "        frames.append(frame_)\n",
    "        if len(frames) == max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    features = feature_extractor.predict(frames)\n",
    "    \n",
    "    file_name = SAVE_DIR + f'train/{label}_{i}.npy'\n",
    "    np.save(file_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "print(len(glob(SAVE_DIR + 'train/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:30<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, elem in tqdm(valid_df.iterrows(),\n",
    "                   total=len(valid_df)):\n",
    "    label = elem['label']\n",
    "    cap = cv2.VideoCapture(\n",
    "        elem['file_path']\n",
    "    )\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_ = frame.copy()\n",
    "        frame_ = cv2.cvtColor(frame_, cv2.COLOR_BGR2RGB)\n",
    "        frame_ = cv2.resize(frame_, (256, 256))\n",
    "        frame_ = frame_.astype('float32')\n",
    "        frame_ = frame_ / 255.\n",
    "\n",
    "        frames.append(frame_)\n",
    "        if len(frames) == max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    features = feature_extractor.predict(frames)\n",
    "    \n",
    "    file_name = SAVE_DIR + f'valid/{label}_{i}.npy'\n",
    "    np.save(file_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(glob(SAVE_DIR + 'valid/*')))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ceb9ecc5f5f802cb05537ec1ae1602a5cb641d69ad11cd1f339e5a39af141e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
